{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attack for MNIST DNN Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YVyxmvku4D-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEkKgcSgu8sI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배치 사이즈 설정\n",
        "batch_size = 64\n",
        "\n",
        "# MNIST 데이터 세트를 이용합니다.\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-06G-EFfu-2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 로더를 이용하여 데이터를 불러올 수 있습니다.\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEHKWi2mu9qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 임의의 이미지 분류 딥 뉴럴 네트워크 선언\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(784, 520) # 입력층\n",
        "        self.l2 = nn.Linear(520, 320)\n",
        "        self.l3 = nn.Linear(320, 240)\n",
        "        self.l4 = nn.Linear(240, 120)\n",
        "        self.l5 = nn.Linear(120, 10) # 10개로 분류\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # (배치 사이즈, 1, 28, 28) 크기의 데이터를 (배치 사이즈, 784) 형태로 변경합니다.\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        return self.l5(x)\n",
        "\n",
        "\n",
        "model = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNAg01Y2vAbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.8f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data))\n",
        "            \n",
        "# 배치 한 번에 대한 data와 target 정보 가져오기\n",
        "get_data = []\n",
        "get_target = []\n",
        "got = False \n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        global got\n",
        "        if not got:\n",
        "          get_data.append(data)\n",
        "          get_target.append(target)\n",
        "          got = True\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += criterion(output, target).data\n",
        "        # get the index of the max\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnqF2sScvC8D",
        "colab_type": "code",
        "outputId": "99b3e43c-addb-48c0-99ce-a628fac57ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 학습 수행\n",
        "for epoch in range(0, 10):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.29774189\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.31107497\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.30224872\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.28736734\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.28284836\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.27490926\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.24955773\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 2.23057199\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 2.14722085\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 1.90413511\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0272, Accuracy: 4427/10000 (44%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.80065191\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.42838001\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.95072317\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.73783684\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.67243677\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.72282821\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.76012862\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.61376834\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.57562184\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.54321486\n",
            "\n",
            "Test set: Average loss: 0.0067, Accuracy: 8717/10000 (87%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.47642353\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.26871383\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.54879725\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.23233993\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.33285114\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.30322838\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.31908777\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.18858074\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.45591229\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.33553505\n",
            "\n",
            "Test set: Average loss: 0.0046, Accuracy: 9146/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.31155950\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.59822035\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.35734630\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.22125749\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.27214047\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.28061131\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.20021445\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.26072219\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.21669146\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.39855397\n",
            "\n",
            "Test set: Average loss: 0.0036, Accuracy: 9307/10000 (93%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.16088244\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.18491034\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.22748566\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.21542290\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.51774853\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.16814673\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.40113342\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.31455007\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.13093467\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.38287202\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy: 9482/10000 (94%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.24665743\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.20359826\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.06437274\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.12874967\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.17599176\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.14884490\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.15352379\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.18971275\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.19855137\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.21942590\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9562/10000 (95%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.06047353\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.11872111\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.28519577\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.08087602\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.03510851\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.20076969\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.05845571\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.16012762\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.06309976\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.07673725\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9598/10000 (95%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.06074602\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.14093739\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.16908780\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.05171902\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.13229623\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.08398627\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.04417183\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.05073702\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.03697236\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.24041031\n",
            "\n",
            "Test set: Average loss: 0.0018, Accuracy: 9674/10000 (96%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.11095224\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.02832038\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.19230264\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.07600899\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.03732330\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.14695248\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.04832342\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.02271957\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.06102514\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.13134828\n",
            "\n",
            "Test set: Average loss: 0.0017, Accuracy: 9683/10000 (96%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.11421780\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.12435957\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.11259864\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.11232007\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.07497924\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.17624053\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.13311107\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.17736199\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.16037504\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.09461965\n",
            "\n",
            "Test set: Average loss: 0.0016, Accuracy: 9707/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSWP-WJEy8H2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FGSM attack code\n",
        "def fgsm_attack(data, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_data = data + epsilon * sign_data_grad\n",
        "    # Return the perturbed image\n",
        "    return perturbed_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_r7D9WHvuMQ",
        "colab_type": "code",
        "outputId": "b8aa023a-297f-4823-f441-2a8e7e6b6012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# FGSM attack code\n",
        "def fgsm_attack(data, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbation = epsilon * sign_data_grad\n",
        "    # Return the perturbed image\n",
        "    return perturbation\n",
        "\n",
        "image_data = get_data[0][0] # 첫 번째 숫자 X\n",
        "print('숫자 이미지 X의 크기:', image_data.size())\n",
        "plt.imshow(image_data.numpy()[0], cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "숫자 이미지 X의 크기: torch.Size([1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff53d848748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADO5JREFUeJzt3V2IXfW5x/Hf76QpiOlFYjUMNpqe\nogerSKKjCMYS9VhyYiEWg9SLkkLJ9CJKCyVU7EVzWaQv1JvAlIbGkmMrpNUoYmNjMQ1qcSJqEmNi\nElIzMW9lhCaCtNGnF7Nsp3H2f+/st7XH5/uBYfZez3p52Mxv1lp77bX/jggByOe/6m4AQD0IP5AU\n4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpD7Vz43Z5uOEQI9FhFuZr6M9v+1ltvfZPmD7gU7WBaC/\n3O5n+23PkrRf0h2SxiW9LOneiHijsAx7fqDH+rHnv1HSgYg4FBF/l/RrSSs6WB+APuok/JdKOjLl\n+Xg17T/YHrE9Znusg20B6LKev+EXEaOSRiUO+4FB0sme/6ikBVOef66aBmAG6CT8L0u6wvbnbX9a\n0tckbelOWwB6re3D/og4a/s+Sb+XNEvShojY07XOAPRU25f62toY5/xAz/XlQz4AZi7CDyRF+IGk\nCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiB\npAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmp7iG5Jsn1Y0mlJH0g6GxHD3WgK\nQO91FP7KrRHx1y6sB0AfcdgPJNVp+EPSVts7bY90oyEA/dHpYf+SiDhq+xJJz9p+MyK2T52h+qfA\nPwZgwDgiurMie52kMxHxo8I83dkYgIYiwq3M1/Zhv+0LbX/mo8eSvixpd7vrA9BfnRz2z5f0O9sf\nref/I+KZrnQFoOe6dtjf0sY47Ad6rueH/QBmNsIPJEX4gaQIP5AU4QeSIvxAUt24qy+FlStXNqyt\nXr26uOw777xTrL///vvF+qZNm4r148ePN6wdOHCguCzyYs8PJEX4gaQIP5AU4QeSIvxAUoQfSIrw\nA0lxS2+LDh061LC2cOHC/jUyjdOnTzes7dmzp4+dDJbx8fGGtYceeqi47NjYWLfb6Rtu6QVQRPiB\npAg/kBThB5Ii/EBShB9IivADSXE/f4tK9+xfe+21xWX37t1brF911VXF+nXXXVesL126tGHtpptu\nKi575MiRYn3BggXFeifOnj1brJ86dapYHxoaanvbb7/9drE+k6/zt4o9P5AU4QeSIvxAUoQfSIrw\nA0kRfiApwg8k1fR+ftsbJH1F0smIuKaaNk/SbyQtlHRY0j0R8W7Tjc3g+/kH2dy5cxvWFi1aVFx2\n586dxfoNN9zQVk+taDZewf79+4v1Zp+fmDdvXsPamjVrisuuX7++WB9k3byf/5eSlp0z7QFJ2yLi\nCknbqucAZpCm4Y+I7ZImzpm8QtLG6vFGSXd1uS8APdbuOf/8iDhWPT4uaX6X+gHQJx1/tj8ionQu\nb3tE0kin2wHQXe3u+U/YHpKk6vfJRjNGxGhEDEfEcJvbAtAD7YZ/i6RV1eNVkp7oTjsA+qVp+G0/\nKulFSf9je9z2NyX9UNIdtt+S9L/VcwAzCN/bj4F19913F+uPPfZYsb579+6GtVtvvbW47MTEuRe4\nZg6+tx9AEeEHkiL8QFKEH0iK8ANJEX4gKS71oTaXXHJJsb5r166Oll+5cmXD2ubNm4vLzmRc6gNQ\nRPiBpAg/kBThB5Ii/EBShB9IivADSTFEN2rT7OuzL7744mL93XfL3xa/b9++8+4pE/b8QFKEH0iK\n8ANJEX4gKcIPJEX4gaQIP5AU9/Ojp26++eaGteeee6647OzZs4v1pUuXFuvbt28v1j+puJ8fQBHh\nB5Ii/EBShB9IivADSRF+ICnCDyTV9H5+2xskfUXSyYi4ppq2TtJqSaeq2R6MiKd71SRmruXLlzes\nNbuOv23btmL9xRdfbKsnTGplz/9LScummf7TiFhU/RB8YIZpGv6I2C5pog+9AOijTs7577P9uu0N\ntud2rSMAfdFu+NdL+oKkRZKOSfpxoxltj9gesz3W5rYA9EBb4Y+IExHxQUR8KOnnkm4szDsaEcMR\nMdxukwC6r63w2x6a8vSrknZ3px0A/dLKpb5HJS2V9Fnb45J+IGmp7UWSQtJhSd/qYY8AeoD7+dGR\nCy64oFjfsWNHw9rVV19dXPa2224r1l944YViPSvu5wdQRPiBpAg/kBThB5Ii/EBShB9IiiG60ZG1\na9cW64sXL25Ye+aZZ4rLcimvt9jzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBS3NKLojvvvLNYf/zx\nx4v19957r2Ft2bLpvhT631566aViHdPjll4ARYQfSIrwA0kRfiApwg8kRfiBpAg/kBT38yd30UUX\nFesPP/xwsT5r1qxi/emnGw/gzHX8erHnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkmt7Pb3uBpEck\nzZcUkkYj4me250n6jaSFkg5Luici3m2yLu7n77Nm1+GbXWu//vrri/WDBw8W66V79psti/Z0837+\ns5K+GxFflHSTpDW2vyjpAUnbIuIKSduq5wBmiKbhj4hjEfFK9fi0pL2SLpW0QtLGaraNku7qVZMA\nuu+8zvltL5S0WNKfJc2PiGNV6bgmTwsAzBAtf7bf9hxJmyV9JyL+Zv/7tCIiotH5vO0RSSOdNgqg\nu1ra89uercngb4qI31aTT9gequpDkk5Ot2xEjEbEcEQMd6NhAN3RNPye3MX/QtLeiPjJlNIWSauq\nx6skPdH99gD0SiuX+pZI+pOkXZI+rCY/qMnz/sckXSbpL5q81DfRZF1c6uuzK6+8slh/8803O1r/\nihUrivUnn3yyo/Xj/LV6qa/pOX9E7JDUaGW3n09TAAYHn/ADkiL8QFKEH0iK8ANJEX4gKcIPJMVX\nd38CXH755Q1rW7du7Wjda9euLdafeuqpjtaP+rDnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkuM7/\nCTAy0vhb0i677LKO1v38888X682+DwKDiz0/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFdf4ZYMmS\nJcX6/fff36dO8EnCnh9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmp6nd/2AkmPSJovKSSNRsTPbK+T\ntFrSqWrWByPi6V41mtktt9xSrM+ZM6ftdR88eLBYP3PmTNvrxmBr5UM+ZyV9NyJesf0ZSTttP1vV\nfhoRP+pdewB6pWn4I+KYpGPV49O290q6tNeNAeit8zrnt71Q0mJJf64m3Wf7ddsbbM9tsMyI7THb\nYx11CqCrWg6/7TmSNkv6TkT8TdJ6SV+QtEiTRwY/nm65iBiNiOGIGO5CvwC6pKXw256tyeBviojf\nSlJEnIiIDyLiQ0k/l3Rj79oE0G1Nw2/bkn4haW9E/GTK9KEps31V0u7utwegV1p5t/9mSV+XtMv2\nq9W0ByXda3uRJi//HZb0rZ50iI689tprxfrtt99erE9MTHSzHQyQVt7t3yHJ05S4pg/MYHzCD0iK\n8ANJEX4gKcIPJEX4gaQIP5CU+znEsm3GcwZ6LCKmuzT/Mez5gaQIP5AU4QeSIvxAUoQfSIrwA0kR\nfiCpfg/R/VdJf5ny/LPVtEE0qL0Nal8SvbWrm71d3uqMff2Qz8c2bo8N6nf7DWpvg9qXRG/tqqs3\nDvuBpAg/kFTd4R+tefslg9rboPYl0Vu7aumt1nN+APWpe88PoCa1hN/2Mtv7bB+w/UAdPTRi+7Dt\nXbZfrXuIsWoYtJO2d0+ZNs/2s7bfqn5PO0xaTb2ts320eu1etb28pt4W2P6j7Tds77H97Wp6ra9d\noa9aXre+H/bbniVpv6Q7JI1LelnSvRHxRl8bacD2YUnDEVH7NWHbX5J0RtIjEXFNNe0hSRMR8cPq\nH+fciPjegPS2TtKZukdurgaUGZo6srSkuyR9QzW+doW+7lENr1sde/4bJR2IiEMR8XdJv5a0ooY+\nBl5EbJd07qgZKyRtrB5v1OQfT9816G0gRMSxiHilenxa0kcjS9f62hX6qkUd4b9U0pEpz8c1WEN+\nh6SttnfaHqm7mWnMr4ZNl6TjkubX2cw0mo7c3E/njCw9MK9dOyNedxtv+H3ckoi4TtL/SVpTHd4O\npJg8ZxukyzUtjdzcL9OMLP0vdb527Y543W11hP+opAVTnn+umjYQIuJo9fukpN9p8EYfPvHRIKnV\n75M19/MvgzRy83QjS2sAXrtBGvG6jvC/LOkK25+3/WlJX5O0pYY+Psb2hdUbMbJ9oaQva/BGH94i\naVX1eJWkJ2rs5T8MysjNjUaWVs2v3cCNeB0Rff+RtFyT7/gflPT9Onpo0Nd/S3qt+tlTd2+SHtXk\nYeA/NPneyDclXSRpm6S3JP1B0rwB6u1XknZJel2TQRuqqbclmjykf13Sq9XP8rpfu0JftbxufMIP\nSIo3/ICkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJPVP82g/p9/JjhUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cakzyE_CzyZd",
        "colab_type": "code",
        "outputId": "dd7cf89b-bdd9-462e-89e6-050424018c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "image_data.requires_grad = True\n",
        "target_value = torch.chunk(get_target[0], 64, dim=0)[0] # 첫 번째 숫자 X의 원래 분류 값\n",
        "expect_value = model(image_data) # 첫 번째 숫자 X의 예측 결과 계산\n",
        "print('X의 판정 결과:', expect_value)\n",
        "print('X의 분류 값:', target_value)\n",
        "\n",
        "# 원래 분류 값에 대한 Loss의 기울기 계산\n",
        "loss = criterion(expect_value, target_value)\n",
        "print('Y에 대한 X의 Loss 값:', loss)\n",
        "\n",
        "# 역전파 수행\n",
        "loss.backward()\n",
        "# 각 차원(픽셀)에 따른 기울기 값 계산\n",
        "data_grad = image_data.grad.data\n",
        "\n",
        "# 그냥 부호만 채택하여 입실론 만큼 곱하기\n",
        "perturbation = fgsm_attack(image_data, 0.25, data_grad)\n",
        "\n",
        "# 만들어진 Perturbation 가져오기\n",
        "perturbation = perturbation[0]\n",
        "output = model(perturbation)\n",
        "print('Perturbation의 예측 결과: ', output)\n",
        "\n",
        "perturbation_image = perturbation.detach().numpy() # Perturbation 이미지 출력을 위한 Numpy 변환\n",
        "plt.imshow(perturbation_image, cmap='gray', vmin=0, vmax=1) # 출력할 때 최소는 0, 최대는 1로 설정해야 정상 동작"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X의 판정 결과: tensor([[ -2.3541,   0.1431,   3.0336,   5.0114,  -8.6109,  -2.4930, -14.8356,\n",
            "          12.9158,   1.0161,   5.5949]], grad_fn=<AddmmBackward>)\n",
            "X의 분류 값: tensor([7])\n",
            "Y에 대한 X의 Loss 값: tensor(0.0011, grad_fn=<NllLossBackward>)\n",
            "Perturbation의 예측 결과:  tensor([[ -0.6863,   0.5825,  -0.5751,   2.1612,  -4.5268,   8.1236,   5.0366,\n",
            "         -10.4269,   4.6869,  -3.3598]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff53d823d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wco+Gi6LV9m4gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFX92g3yuJi-",
        "colab_type": "code",
        "outputId": "06b36621-3ee7-4bf1-e1dd-1ed236ed60d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "# 최종적으로 만들어진 Adversarial Example\n",
        "adversarial_example = image_data + perturbation\n",
        "adversarial_example = torch.clamp(adversarial_example, 0, 1) # 0부터 1사이의 값이 아니라면 가지치기\n",
        "plt.imshow(adversarial_example.detach().numpy()[0], cmap='gray', vmin=0, vmax=1)\n",
        "\n",
        "# Adversarial Example의 예측 결과 계산\n",
        "expect_value = model(adversarial_example)\n",
        "print('Adversarial Example의 판정 결과:', expect_value)\n",
        "print('가장 가까운 숫자:', expect_value.data.max(1, keepdim=True)[1])\n",
        "\n",
        "# 원래 분류 값에 대한 Loss의 기울기 계산\n",
        "loss = criterion(expect_value, target_value)\n",
        "print('Y에 대한 Adversarial Example의 Loss 값:', loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adversarial Example의 판정 결과: tensor([[ -0.2700,  -1.1158,  -0.1620,   9.5920, -13.2958,   9.7336,  -4.0752,\n",
            "          -7.0577,   6.1908,   1.4546]], grad_fn=<AddmmBackward>)\n",
            "가장 가까운 숫자: tensor([[5]])\n",
            "Y에 대한 Adversarial Example의 Loss 값: tensor(17.4318, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANBEX4gKMIPBEX4gaD+HxhrvxZ5z9kiAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uf_Onyd8t4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}