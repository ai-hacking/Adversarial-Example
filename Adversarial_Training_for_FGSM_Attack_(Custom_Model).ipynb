{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial Training for FGSM (Custom Model).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOKvqUyqWuWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9k7EnXFW4ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배치 사이즈 설정\n",
        "batch_size = 64\n",
        "\n",
        "# MNIST 데이터 세트를 이용합니다.\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYt-lzgqW6Nj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 로더를 이용하여 데이터를 불러올 수 있습니다.\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibBBVkjRW6xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# FGSM attack code\n",
        "def fgsm_attack(data, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbation = epsilon * sign_data_grad\n",
        "    # Return the perturbed image\n",
        "    return perturbation\n",
        "  \n",
        "def make_adversarial_example(model, image_data, target_data):\n",
        "  image_data.requires_grad = True\n",
        "  target_value = target_data\n",
        "  expect_value = model(image_data) # 첫 번째 숫자 X의 예측 결과 계산\n",
        "  # print('X의 분류 값:', target_value)\n",
        "  \n",
        "  # 원래 분류 값에 대한 Loss의 기울기 계산\n",
        "  # print(expect_value)\n",
        "  loss = criterion(expect_value, target_value)\n",
        "  # print('Y에 대한 X의 Loss 값:', loss)\n",
        "\n",
        "  # 역전파 수행\n",
        "  loss.backward()\n",
        "  # 각 차원(픽셀)에 따른 기울기 값 계산\n",
        "  data_grad = image_data.grad.data\n",
        "\n",
        "  # 그냥 부호만 채택하여 입실론 만큼 곱하기\n",
        "  perturbation = fgsm_attack(image_data, 0.25, data_grad)\n",
        "\n",
        "  # 만들어진 Perturbation 가져오기\n",
        "  output = model(perturbation)\n",
        "  # print('Perturbation의 예측 결과: ', output)\n",
        "  \n",
        "  # 최종적으로 만들어진 Adversarial Example\n",
        "  adversarial_example = image_data + perturbation\n",
        "  adversarial_example = torch.clamp(adversarial_example, 0, 1) # 0부터 1사이의 값이 아니라면 가지치기\n",
        "  return adversarial_example"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsRhW0xBW8Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 임의의 이미지 분류 딥 뉴럴 네트워크 선언\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(784, 520) # 입력층\n",
        "        self.l2 = nn.Linear(520, 320)\n",
        "        self.l3 = nn.Linear(320, 240)\n",
        "        self.l4 = nn.Linear(240, 120)\n",
        "        self.l5 = nn.Linear(120, 10) # 10개로 분류\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # (배치 사이즈, 1, 28, 28) 크기의 데이터를 (배치 사이즈, 784) 형태로 변경합니다.\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        return self.l5(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kZrBkmRW_GX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basic_model = Net()\n",
        "adversarial_training_model = Net()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "basic_model_optimizer = optim.SGD(basic_model.parameters(), lr=0.01, momentum=0.5)\n",
        "adversarial_training_model_optimizer = optim.SGD(adversarial_training_model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmfKBKYgXDmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, model):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        basic_model_optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        basic_model_optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.8f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data))\n",
        "            \n",
        "def adversarial_train(epoch, model):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        \n",
        "        # 일단 원래 모델로 학습\n",
        "        adversarial_training_model_optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        adversarial_training_model_optimizer.step()\n",
        "        \n",
        "        # 배치 사이즈만큼(64개)의 FGSM Perturbation을 공통 Loss를 이용해 한 번에 생성 및 학습\n",
        "        adversarial_training_model_optimizer.zero_grad()\n",
        "        adversarial_example = make_adversarial_example(model, data, target)\n",
        "        output = model(adversarial_example)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        adversarial_training_model_optimizer.step()\n",
        "       \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.8f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data))\n",
        "\n",
        "def test(model):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += criterion(output, target).data\n",
        "        # get the index of the max\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    \n",
        "def adversarial_test(model):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        # 배치 사이즈만큼(64개)의 FGSM Perturbation을 공통 Loss를 이용해 한 번에 생성 및 학습\n",
        "        #\n",
        "        #\n",
        "        # 여기에서는 basic_model이 만든 Adversarial Example과 비교해야 함! (공격자의 예상)\n",
        "        #\n",
        "        #\n",
        "        adversarial_example = make_adversarial_example(basic_model, data, target) \n",
        "        output = model(adversarial_example)\n",
        "        # sum up batch loss\n",
        "        test_loss += criterion(output, target).data\n",
        "        # get the index of the max\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOdbs4pZXWbj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9681900-4bb4-4d2b-8846-e8e81df5f002"
      },
      "source": [
        "# 이후에 Basic Model에 대한 학습 수행\n",
        "for epoch in range(0, 10):\n",
        "  train(epoch, basic_model) # Basic Model을 학습시킵니다.\n",
        "  test(basic_model) # Basic Model의 학습 결과를 테스트합니다.\n",
        "  adversarial_test(basic_model) # Basic Model에서 만들어진 Adversarial Example을 이용해 테스트합니다. (무슨 짓을 해도 0%에 가깝게 나옴.)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.30006027\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.29364729\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.30473137\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.27922869\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.27826762\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.25849032\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.22479916\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 2.10946083\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 1.87134027\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 1.20223820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0161, Accuracy: 6894/10000 (68%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0640, Accuracy: 64/10000 (0%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1.00229084\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.68164521\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.81914812\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.56392592\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.73911738\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.37785628\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.33097145\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.35947847\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.31737751\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.35816699\n",
            "\n",
            "Test set: Average loss: 0.0064, Accuracy: 8801/10000 (88%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1410, Accuracy: 55/10000 (0%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.39026177\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.47278899\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.40219900\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.44740489\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.32671204\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.41729996\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.20317356\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.21027726\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.35278755\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.21858527\n",
            "\n",
            "Test set: Average loss: 0.0046, Accuracy: 9161/10000 (91%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1609, Accuracy: 77/10000 (0%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.32808876\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.18951632\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.20711993\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.28937164\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.08647721\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.22968781\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.34267437\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.15794784\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.28731045\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.18506044\n",
            "\n",
            "Test set: Average loss: 0.0035, Accuracy: 9342/10000 (93%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1664, Accuracy: 31/10000 (0%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.17190672\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.24650028\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.18789260\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.31509325\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.20603605\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.27201307\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.14221053\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.08939213\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.20009707\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.16920605\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy: 9445/10000 (94%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1716, Accuracy: 19/10000 (0%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.24784309\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.23755500\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.24193262\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.18949892\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.13123615\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.14012378\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.13206068\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.13638729\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.10192864\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.03524190\n",
            "\n",
            "Test set: Average loss: 0.0023, Accuracy: 9561/10000 (95%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1832, Accuracy: 9/10000 (0%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.12785159\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.07623991\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.06297474\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.06564944\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.06361396\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.15803690\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.12553859\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.17418227\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.14460343\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.13676982\n",
            "\n",
            "Test set: Average loss: 0.0020, Accuracy: 9622/10000 (96%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.1964, Accuracy: 8/10000 (0%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.16992213\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.07098596\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.15301144\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.15361184\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.14639053\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.05386214\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.09720901\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.03235336\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.19551544\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.09981720\n",
            "\n",
            "Test set: Average loss: 0.0018, Accuracy: 9664/10000 (96%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.2035, Accuracy: 9/10000 (0%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.14092033\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.14051798\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.04371372\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.07500786\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.01928028\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.09623129\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.09697715\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.08990223\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.02627636\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.08124661\n",
            "\n",
            "Test set: Average loss: 0.0019, Accuracy: 9627/10000 (96%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.2210, Accuracy: 7/10000 (0%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.02207537\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.04697046\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.13288914\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.04222498\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.09970722\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.02411916\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.08880466\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.02157147\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.03757659\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.02225135\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9714/10000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.2241, Accuracy: 24/10000 (0%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApVjkFGr0B_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdV08nFlaC84",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c9698c9-3424-4c3d-ff96-8ca441e67b22"
      },
      "source": [
        "# 먼저 Adversarial Training Model에 대한 학습 수행 (기본 이미지와 Adversarial Examples을 1/2씩 섞어서 학습 수행.)\n",
        "for epoch in range(0, 10):\n",
        "  adversarial_train(epoch, adversarial_training_model) # Adversarial Training을 이용해 학습 진행\n",
        "  test(adversarial_training_model) # 기본적인 이미지를 잘 분류하는지 평가\n",
        "  adversarial_test(adversarial_training_model) # Basic Model에서 만들어진 Adversarial Example로 평가"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.33780551\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.31732774\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.31209946\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 2.30480385\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 2.29919076\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 2.31758857\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 2.32805824\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 2.40127325\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 2.73711610\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 2.54492998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0114, Accuracy: 7704/10000 (77%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0250, Accuracy: 4377/10000 (43%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.43531513\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.24358582\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.30073643\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.17466354\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.89060605\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.61186421\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.54261088\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.90697396\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.54866254\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.69497490\n",
            "\n",
            "Test set: Average loss: 0.0044, Accuracy: 9213/10000 (92%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0236, Accuracy: 4926/10000 (49%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.20283675\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.68101048\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.46675360\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.18337274\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.45418155\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.13972211\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.36402440\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.02663004\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.83598518\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.98422992\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy: 9505/10000 (95%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0219, Accuracy: 5760/10000 (57%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.92908603\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.08192480\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.89652830\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.04882002\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.84987479\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.24939752\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.96847463\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.15786266\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.72656292\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.92754287\n",
            "\n",
            "Test set: Average loss: 0.0022, Accuracy: 9590/10000 (95%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0220, Accuracy: 6094/10000 (60%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.88148659\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.85190809\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.64600641\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.62006879\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.94651091\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.91656554\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.95670938\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.77568913\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.62963223\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.88939983\n",
            "\n",
            "Test set: Average loss: 0.0021, Accuracy: 9604/10000 (96%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0221, Accuracy: 6188/10000 (61%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.89311659\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.75078183\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.66494954\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.87552822\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.72177249\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.76364529\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.83327484\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.57090890\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.74396288\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.67422277\n",
            "\n",
            "Test set: Average loss: 0.0017, Accuracy: 9680/10000 (96%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0226, Accuracy: 6378/10000 (63%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.56035388\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.46648952\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.98170596\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.63317430\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.61751789\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.56853199\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.51873207\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.63469481\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.55676347\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.91711992\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9767/10000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 6736/10000 (67%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.80238318\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.80265933\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.76631445\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.64504910\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.41177747\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.62212324\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.57329792\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.53452170\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.42278540\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.68368953\n",
            "\n",
            "Test set: Average loss: 0.0014, Accuracy: 9714/10000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0227, Accuracy: 6605/10000 (66%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.33804536\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.47415394\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.62946963\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.86637211\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.75939387\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.56719565\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.48811764\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.65117651\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.67925853\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.61249399\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9697/10000 (96%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0237, Accuracy: 6452/10000 (64%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.63701069\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.50664330\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.48000175\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.61527359\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.56231767\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.41013467\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.58847380\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.71955717\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.61715335\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.29658151\n",
            "\n",
            "Test set: Average loss: 0.0011, Accuracy: 9772/10000 (97%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0226, Accuracy: 6502/10000 (65%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_na-AxFZa_sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}